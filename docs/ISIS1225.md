---
created: 2025-07-29T23:03:51
type: main
status: active
Teacher:
art:
inicio:
final:
credits: 3
NRC:
nota:
place:
---
#academy/202520/ISIS1225 #UAndes #class   
___
# [ISIS1225](https://eerosales24.github.io/eda_2025_20/#/)

## Cronograma
___
```tasks
not done
sort by priority
sort by tag
short mode
group by due
tags includes #academy/202520/ISIS1225   
```
### Ex√°menes
- [ ] #academy/202520/ISIS1225 EVA1 ‚è´ üìÖ 2025-09-04 
	- [ ] Verificar presentaciones
	- [ ] Tener muy claro casos espec√≠ficos de c√≥digo
	- [ ] Estudiar el bono que nunca fue
	- [ ] Estudiar estructuras de los laboratorios
	- [ ] array_list
	- [ ] single_linked_lists
- [ ] #academy/202520/ISIS1225 EVA2 ‚è´ üìÖ 2025-10-09 
- [ ] #academy/202520/ISIS1225 EVA3 ‚è´ üìÖ 2025-11-06 
- [ ] #academy/202520/ISIS1225 EVA4 ‚è´ üìÖ 2025-12-01 
### Retos
- [x] #academy/202520/ISIS1225 Reto1 release üìÖ 2025-08-21 ‚úÖ 2025-08-20
- [ ] #academy/202520/ISIS1225 Reto2 release üìÖ 2025-09-15
- [ ] #academy/202520/ISIS1225 Reto3 release üìÖ 2025-10-16
- [ ] #academy/202520/ISIS1225 Reto4 release üìÖ 2025-11-11
- [ ] #academy/202520/ISIS1225 Reto1 entrega üîº üìÖ 2025-09-10
- [ ] #academy/202520/ISIS1225 Reto2 entregaüîº üìÖ 2025-10-15
- [ ] #academy/202520/ISIS1225 Reto3 entregaüîº üìÖ 2025-11-12 
- [ ] #academy/202520/ISIS1225 Reto4 entregaüîº üìÖ 2025-12-03 
### Laboratorios

- [x] #academy/202520/ISIS1225 LAB1 release üìÖ 2025-08-07 ‚úÖ 2025-08-07
- [x] #academy/202520/ISIS1225 LAB1 entrega üìÖ 2025-08-15 ‚úÖ 2025-08-14

- [x] #academy/202520/ISIS1225 LAB2 release üìÖ 2025-08-14 ‚úÖ 2025-08-14
- [x] #academy/202520/ISIS1225 LAB2 entrega üìÖ 2025-08-20 ‚úÖ 2025-08-20

- [x] #academy/202520/ISIS1225 LAB3 release üìÖ 2025-08-21 ‚úÖ 2025-08-20
- [x] #academy/202520/ISIS1225 LAB3 entrega üìÖ 2025-08-27 ‚úÖ 2025-08-26

- [ ] #academy/202520/ISIS1225 LAB4 release üìÖ 2025-08-28  
- [ ] #academy/202520/ISIS1225 LAB4 entrega üìÖ 2025-09-03

- [ ] #academy/202520/ISIS1225 LAB5 parte 1 release üìÖ 2025-09-11  
- [ ] #academy/202520/ISIS1225 LAB5 parte 1 entrega üìÖ 2025-09-17

- [ ] #academy/202520/ISIS1225 LAB5 parte 2 release üìÖ 2025-09-18  
- [ ] #academy/202520/ISIS1225 LAB5 parte 2 entrega üìÖ 2025-09-24

- [ ] #academy/202520/ISIS1225 LAB6 release üìÖ 2025-09-25  
- [ ] #academy/202520/ISIS1225 LAB6 entrega üìÖ 2025-10-01

- [ ] #academy/202520/ISIS1225 LAB7 release üìÖ 2025-10-16  
- [ ] #academy/202520/ISIS1225 LAB7 entrega üìÖ 2025-10-22

- [ ] #academy/202520/ISIS1225 LAB8 release üìÖ 2025-10-23  
- [ ] #academy/202520/ISIS1225 LAB8 entrega üìÖ 2025-10-29

- [ ] #academy/202520/ISIS1225 LAB9 release üìÖ 2025-10-30  
- [ ] #academy/202520/ISIS1225 LAB9 entrega üìÖ 2025-11-05

- [ ] #academy/202520/ISIS1225 LAB10 parte 1 release üìÖ 2025-11-13  
- [ ] #academy/202520/ISIS1225 LAB10 parte 1 entrega üìÖ 2025-11-19

- [ ] #academy/202520/ISIS1225 LAB10 parte 2 release üìÖ 2025-11-20  
- [ ] #academy/202520/ISIS1225 LAB10 parte 2 entrega üìÖ 2025-11-26

## W01M1
* La idea del curso es organizar datos
* Cumplir restricciones y crit. de calidad
	* Tiempo
	* Espacio
* Los datos se pueden organizar en
	* Listas
	* Pilas
	* Colas
* Y las estructuras son 
	* Arboles
	* Tablas (Hash)
	* Grafos
### Arquitectura de aplicaci√≥n
* Se divide en **dos**
	* La ==vista==, parte necesario para que el usuario haga uso de la aplicaci√≥n
	* La ==l√≥gica==, realiza las op. sobre los datos y NO **DEPENDE DE LA VISTA**
>[!note] La l√≥gica es as√≠ "Vista <= L√≥gica <= Modelos <= Datos"

### Uso de GIT
* Tendremos tres estados
	* modified
	* staged
	* committed
### Algoritmos y complejidad
Caracter√≠sticas:
- Precisos
- Correctos 
- Determin√≠sticos
- Finito
Cualidades:
- General
- Eficiente
Siendo as√≠ separamos el an√°lisis de algoritmos en dos categor√≠as importantes, _temporal_ y **espacial**.
## W01M2
* El algoritmo de busqueda binar√≠a es un ejemplo de un algoritmo m√°s eficiente que otro en otra tarea... ¬øPero porque?
### Tiempo de ejecuci√≠on
* No todos los algoritmos vana  ser iguales, y vamos a ver que estos tienen una complejidad que involucra el espacio en memoria que ocupan y el tiempo que tardan en cumplir su tarea.
* ### Aproximaci√≥n a prior√≠
- No depende del hardware ni de la ejecuci√≥n.
    
- Usa y considera **todos los datos**.
    
- Tres notaciones principales:
    
    - **Big Theta (Œò):** Crecimiento pr√°cticamente igual en todos los casos.
        
    - **Big Omega (Œ©):** Crecimiento m√≠nimo garantizado (mejor caso).
        
    - **Big O (O):** Crecimiento m√°ximo (peor caso).
        

---

**7 √≥rdenes de crecimiento temporal t√≠picos**

1. **O(1) ‚Äì Constante:**
    
    - Tiempo no depende del tama√±o de los datos.
        
    - Ejemplo: `len(lista)`, comparaciones, m√≥dulo.
        
    - Todas las operaciones primitivas son constantes.
        
2. **O(n) ‚Äì Lineal:**
    
    - Tiempo crece proporcionalmente con la cantidad de datos.
        
    - Ejemplo: recorrer una lista una vez.
        
    - _Big O_ suele considerar el **peor caso**.
        
3. **O(log n) ‚Äì Logar√≠tmico:**
    
    - Crecimiento lento del tiempo con respecto al tama√±o.
        
    - Aparece en divisiones sucesivas y algoritmos tipo b√∫squeda binaria.
        
4. **O(n log n) ‚Äì Lineal√≠tmico:**
    
    - Ejemplo t√≠pico: algoritmos de ordenamiento eficientes.
        
5. **O(n¬≤) ‚Äì Cuadr√°tico**
    
6. **O(n¬≥) ‚Äì C√∫bico**
    
7. **O(b‚Åø) ‚Äì Exponencial**
## W02M1
### Aproximaci√≥n (emp√≠rica a posteriori)
**Ventajas**
* Realista
* Sencilla
**Desventajas**
* Depende del entorno
	* Del hardware, S.O., programas concurrentes, etc. 
* No se puede generalizar
	* Informaci√≥n limitada a tama√±os de entrada espec√≠ficos
		* No aplica a todos los tama√±os
* Influencia de factores externos
* Carga del sistema y gesti√≥n de memoria pueden distorsionar resultados.
### Complejidad Espacial
* Mide la memoria usada por un algoritmo en relaci√≥n al tama√±o de entrada
* Generalmente basado en el peor caso de uso de memoria
* Incluye la memoria usada por
	* Variables 
	* Asignaciones din√°micas
	* ==Estructuras de datos==
#### Espacio constante O(1)
* El espacio no depende del tama√±o de la entrada
```run-python
def suma(num1, num2):
	suma = num1 + num2
	return suma
print(suma(2,2))
```
* Es idenpendiente del tamao de `num1` y `num2`
	* Solo necesita espacio constante para `suma`
#### Espacio lineal O(n)
* El espacio crece linealmente con el tama√±o de la entrada
```run-python
lista = [1,2,3]
def duplicar_lista(lista):
	lista_duplicada = []
	for elemento in lista:
		lista_duplicada.append(elemento * 2)
	return lista_duplicada
print(duplicar_lista(lista))
```
* El espacio necesario para `lista_duplicada` es igual al de la lista que estamos intentando duplicar, por lo tanto **crece linealmente**.
#### Espacio auxiliar
* Memoria adicional aparte de la entrada
```run-python
lista = [5,7,89,3,5]
def ordenar_lista(lista):
	lista_ordenada = sorted(lista)
	return lista_ordenada
print(ordenar_lista(lista))
```
* La `lista_ordenada` es una copia de la lista
	* Resultado en un espacio adicional
		* Proporcional al tama√±o de lista original

>[!question] No entiendo la diferencia entre espacio lineal O(n) y el espacio auxiliar

Diferencia entre **O(n) espacio** y **espacio auxiliar O(n)**
* ***Espacio total**: Toda la memoria que usa el algoritmo (entrada + salida + variables temporales).
* ***Espacio auxiliar**: Memoria **extra** necesaria aparte de la entrada.
* 
| Caso | Entrada (`n`) | Memoria adicional | Espacio total | Espacio auxiliar |
|------|---------------|------------------|---------------|------------------|
| Duplicar lista | `n` | `n` | `O(n)` | `O(n)` |
| Ordenar lista (copia) | `n` | `n` | `O(n)` | `O(n)` |
| Ordenar in-place | `n` | constante | `O(n)` | `O(1)` |

Conclusi√≥n: 
- **O(n) espacio**: Memoria total crece proporcionalmente a `n`.
- **Espacio auxiliar O(n)**: Memoria extra (aparte de la entrada) crece proporcionalmente a `n`.
- Un algoritmo puede tener **espacio total O(n)** pero **auxiliar O(1)** si modifica la entrada directamente.

### Recursividad
* La funci√≥n se invoca a s√≠ misma
	* Resuelve instancia m√°s peque√±a que el problema general
* En ejemplo cl√°sico son las mu√±ecas rusas
	* Versiones m√°s peque√±as anidadas
	* Profundidad **finita**
* Como en [[MATE1102]] hay dos casos
	* Caso base
		* Condici√≥n que detiene la recursi√≥n
		* La funci√≥n no se invoca a si misma
	* Caso recursivo
		* Funci√≥n que se invoca a s√≠ misma
		* Es una versi√≥n ==m√°s peque√±a== del problema
### Metodolog√≠a de desarollo de sofware
Aqu√≠ el orden importa
>[!warning] An√°lisis > Dise√±o > Construcci√≥n > Pruebas
#### An√°lisis
1. Identificar y especificar el problema
2. Identificar restrucciones
3. Documentar
* La idea es planear desde antes que es lo que se va a realizar y que tiene que hacer la funci√≥n que vamos a realizar
* Hay que entender su **proposito** y adem√°s que entradas y salidas vamos a esperar/dise√±ar
* Finalmente tambi√©n es importante pensar en las restricciones del mismo y como estas van a afectar el dise√±o. Estas aplican tanto para ==entrada como para salida==

* Una vez hemos hecho e identificado el profeso arriba ya podemos escribir la documentaci√≥n:

```run-python

"""
Calcula el factorial de un n√∫mero (n!)

param numero: El n√∫mero positivo para calcular su factorial
:type numero: int

:returns: El factorial del n√∫mero proporcionado
:rtype: int
"""
# Nota este de arriba es el formato de documentaci√≥n para EDA.

```

Note que la documentaci√≥n refleja claramente las restricciones y la naturaleza de la entrada/salida.



#### Dise√±o
1. Formular ejemplo
	1. Casos significativos y no redundantes
2. Dise√±ar algoritmo
3. Dise√±ar y documentar las pruebas

`
factorial (0) = 1
factorial (1) = 1
factorial (2) = 2
.... etc.
`
## Repaso Bono W02M1
```run-python
import matplotlib.pyplot as plt
import numpy as np

# Valores de n
n_values = np.arange(1, 20)

# Crecimientos
linear = n_values
quadratic = n_values**2
nlogn = n_values * np.log2(n_values)
exponential = 2**n_values

plt.figure(figsize=(8,5))
plt.plot(n_values, linear, label=r"$n$", marker='o')
plt.plot(n_values, quadratic, label=r"$n^2$", marker='o')
plt.plot(n_values, nlogn, label=r"$n \log n$", marker='o')
plt.plot(n_values, exponential, label=r"$2^n$", marker='o')

plt.ylim(0, 200)  # limitar para ver las curvas m√°s peque√±as
plt.xlabel("Tama√±o de entrada n")
plt.ylabel("N√∫mero de operaciones (escala lineal)")
plt.title("Comparaci√≥n de √≥rdenes de crecimiento")
plt.legend()
plt.grid(True)
plt.show()

```
Aqu√≠ ves c√≥mo crecen las funciones:

- **O(n)** crece de forma lineal.
    
- **O(n log n)** crece un poco m√°s r√°pido, pero sigue siendo mucho menor que cuadr√°tica para valores grandes.
    
- **O(n¬≤)** crece muy r√°pido.
    
- **O(2‚Åø)** explota enseguida, incluso con n peque√±o.
    

Esto es por lo que un algoritmo **exponencial** se vuelve impracticable muy r√°pido.
### Complejidad temporal
```run-python
lista = [7,6,4,3,1,5,9]
elemento_a_buscar = 5
def busqueda_secuencial(lista, elemento_a_buscar):
	resultado = None
	encontrado = False
	indice = 0 
	while indice < len(lista) and not encontrado:
		if lista[indice] == elemento_a_buscar:
			resultado = lista[indice]  
			encontrado = True
		indice += 1 

	return resultado
print(busqueda_secuencial(lista, elemento_a_buscar))
```
y ahora comparemoslo al algoritmo de busqueda binar√≠a
```run-python
lista = [1,2,3,4,5,6]
elemento_a_buscar = 5
def busqueda_binaria(lista, elemento_a_buscar):
	inicio, fin = 0, len(lista) - 1
	resultado = None
	encontrado = False
	while inicio <= fin and not encontrado:
		medio = (inicio + fin)//2
		if lista[medio] < elemento_a_buscar:
			inicio = medio  + 1
		elif lista[medio] > elemento_a_buscar:
			inicio = medio  - 1
		else:
			resultado = lista[medio]
			encontrado = True
	return resultado
print(busqueda_binaria(lista, elemento_a_buscar))

```
* Uno es mucho m√°s r√°pido que el otro, pero porque exactamente....
* Partimos del m√©todo cient√≠fico


>[!note] Complejidad temporal
> Tiempo total de ejecuci√≥n = N√∫mero de operaciones requeridas * Tiempo por operaci√≥n

>[!note] Complejidad espacial
> Memoria total = N√∫mero objetos requeridos * Memoria por objeto

#### Aproximaci√≥n te√≥rica (a prori)
* Determinaci√≥n aproximaci√≥n matem√°tica
* Ventajas: No requiere la implementaci√≥n del algoritmo
* No depende del hardware o sofware de soporte
	* Independiente del tama√±o de los datos de entrada
	* Considera todos los datos de entrada
#### Notaciones para la complejidad algoritmica
1. Big Theta $\Theta$
	1. Que es la que mide exactamente como se comporta el algoritmo en terminos de tiempo vs tama√±o de datos (L√≠mite asintotico de los datos)
	2. Poco usada porque es muy dificil de obtener
	3. Baja aplicabilidad
2. Big Omega $\Omega$
	1. Es b√°sicamente el l√≠mite inferior asint√≥tico 
3. Big O $O$
	1. Establece el l√≠mite superior asint√≥tico
	2. Se usa para describir la complejidad m√°xima de un algoritmo, y siempre va por arriba del estimado en la gr√°fica de tiempo vs tama√±o de los datos.
	3. Siempre estima por arriba. Es MUY INFORMATIVO.
#### Orden constante $O(1)$
	1.  Tiempo constante y predecible
	2. No aumenta con el tama√±o de la entrada, osea indpendiente del tama√±o de los datos
Ejemplos de operaciones primitivas o constantes:
![[Pasted image 20250811200137.png]]

Ahora un ejemplo de algoritmo de orden constante

```run-python
def es_par(n):
    """
    Determina si un n√∫mero es par o impar.
    Args:
        n (int): el n√∫mero a verificar.
    Returns:
        bool: True si n es par, False si n es impar.
    """
    return n % 2 == 0
print(es_par(5))
```

* Note que realmente solo se esta usando funciones que tienen ordenes constantes $O(1)$

Quiz1
```run-python
lista = [1,2,3,4,5,6]
pos = 0
def dar_elemento_en_posicion(lista, pos):
    """
    Retorna el elemento en la posici√≥n especificada de la lista.

    Args:
        lista (list): La lista de la cual obtener el elemento.
        pos (int): La posici√≥n del elemento a retornar.

    Returns:
        El elemento en la posici√≥n dada o None si la posici√≥n es inv√°lida.
    """
    resultado = None
    if 0 <= pos < len(lista):
        resultado = lista[pos]
    return resultado
print(dar_elemento_en_posicion(lista, pos))
```
Este como vemos tiene una complejidad temporal de $O(1)$ porque solo se utilizan operaciones primitivas que se repiten una unica vez. No hay ciclos y no, if no es un ciclo. Todas son comparaciones. Y recuerde ==PRINT() NO ES $O(1)$==.

#### Orden lineal $O(n)$
- Caracter√≠sticas
    - Tiempo crece proporcionalmente con la cantidad de datos
    - T√≠picamente, cada elemento se procesa una vez
- Ventajas
    - Simple de entender e interpretar
    - Eficiente para vol√∫menes de datos peque√±os o medianos
- Desventajas
    - Ineficiente a gran escala
un ejemplo es:

```run-python
for elemento in lista:
    # Expresiones O(1)
```
Es f√°cil ver como el tiempo requerido para correrlo va a crecer de manera lineal con la cantidad de datos.
```run-python
def sumar_elementos(lista):
    '''
    Suma todos los elementos de una lista.

    Args:
        arreglo (list): Una lista de n√∫meros (int o float).

    Returns:
        int o float: La suma de todos los elementos en la lista.
    '''
    total = 0
    for elemento in lista:
        total += elemento
    return total
```
De nuevo es lineal porque note que las operaciones $O(1)$ se estan repitiendo n veces, las n veces corresponden a los n elementos de la lista.

```run-python
def sumar_elementos(lista):
    total = 0
    for elemento in lista:
        total += elemento
    return total
```

Otro ejemplo quee es lineal pues va a depender de que tantos elementos busquemos sumar, esta es una buena forma de verificar si el comportamiento que vemos es $O(1)$ o $O(n)$.

Y acon que haya una sola operaci√≥n que se repita `n` veces es suficiente para que sea un orden lineal.
}

#### An√°lisis de algoritmos por casos
- El an√°lisis de algoritmos no constantes, t√≠picamente considera tres casos:
- **Peor caso:**
    - Input que requiere el m√°ximo tiempo de ejecuci√≥n del algoritmo
- **Mejor caso:**
    - Input que requiere el m√≠nimo tiempo de ejecuci√≥n del algoritmo
- **Caso promedio:**
    - Estimaci√≥n promedio del tiempo de ejecuci√≥n
        - Considerando la distribuci√≥n probabil√≠stica del input
Por ejemplo:
```run-python
for elemento in lista:
    if elemento == valor_buscado:
        # Valor encontrado
        # Fin de b√∫squeda
```
En este caso, si el primer valor de la lista es el valor que buscamos vamos a obtener el mejor de los casos, osea un $O(1)$, pero lo m√°s probable es que esto no sea verdad y que tengamos que repetir la igualdad del if por cada elemento (hay un for entonces repetimos la instrucci√≥n), esto quiere decir que vamos a terminar con un $O(n)$ en promedio y el peor de los casos no vamos a encontrar el dato pero si estamos revisando cada cosa entonces va a ser $O(n)$ tambi√©n.
>[!tip] Recuerde que la notaci√≥n Bif $O$ usa siempre el peor caso

Por ejemplo en el caso de la busqueda_secuencial encontramos que en efecto se trata de que no encontraremos el dato, y en notaci√≥n $O$, esto quiere decir que va a tener una complejidad $O(n)$.

#### Orden logar√≠tmico O(log n)
- Caracter√≠sticas
    - Tiempo incrementa lentamente a medida que crecen los datos
- Ventajas
    - Eficiente para grandes cantidades de datos
- Desventajas
    - Mayor complejidad de implementaci√≥n
    - Costos de ordenamiento y mantenimiento de datos
___
- Caracter√≠stica clave:
    - Reducci√≥n significativa y r√°pida del rango de operaci√≥n
- Explicaci√≥n:
    - Variable se `i` divide por `c` en cada iteraci√≥n
        - Disminuci√≥n hasta que `i <= 1`
- Iteraciones limitadas a logc de `n`
    - En complejidad temporal, no importa el coeficiente constante de log
        - Entonces, la complejidad logar√≠tmica es **O(log n)**
Ejemplo:
```run-python
i = n
while i > 0:
    # Expresiones O(1)
    i /= c  # √≥ divisi√≥n entera
```
```run-python
i = 1
while i < n:
    # Expresiones O(1)
    i *= c
```
Son b√°sicamente expresiones O(1), pero note que hay una divisi√≥n o una exponencial que me va cortando las posibilidades hasta que el algoritmo termina de correr, as√≠ b√°sicamente aplicando la estrategia de divide y venceras.

Recordemos entonces que la ==b√∫squeda binar√≠a== va a tener este tipo e complejidad temporal.

>[!tldr] Caracter√≠stica clave
> Itera reduciendo la b√∫squeda a la mitad en cada paso

#### B√∫squeda secuencial vs b√∫squeda binaria (2/2)
- B√∫squeda secuencial:
    
    - **Orden lineal O(n):**
        - Simple pero ineficiente para grandes cantidades de datos
- B√∫squeda binaria:
    
    - **Orden logar√≠tmico O(log n):**
        - M√°s complejo y requiere ordenamiento, pero,
            - Muy eficiente para grandes cantidades de datos
#### Orden linear√≠tmico O(n log(n))
- Caracter√≠sticas
    - Combinaci√≥n de lineal y logar√≠tmico:
        - Tiempo crece proporcional a n y a n log n
    - M√°s r√°pido que lineal para grandes n, pero m√°s lento que logar√≠tmico
- Ventajas
    - Eficiente de moderadas a grandes vol√∫menes de datos
- Desventajas
    - Mayor complejidad de implementaci√≥n
    - M√°s lento que algoritmos logar√≠tmicos puros
    - Puede ser muy costoso para algunos vol√∫menes de datos grandes
Ejemplo:
```run-python
for i in range(1, n):  # Parte lineal
    # Expresiones O(1)
    j = 1
    while j < n:  # Parte logar√≠tmica
        # Expresiones O(1)
        j *= 2
```
Otro ejemplo un poco m√°s elaborado:
```run-python
def buscar_en_sublistas_con_bbinaria(listas, elemento_buscado):
    """
    Busca un elemento en cada sublista ordenada de la lista principal.

    Args:
        listas (list of list): Lista de sublistas ordenadas.
        elemento_buscado: el elemento a buscar.

    Returns:
        tuple: (√≠ndice_lista_principal, √≠ndice_sublista) del elemento
        encontrado, o (None, None) si el elemento no se encuentra.
    """
    resultado = (None, None)
    encontrado = False

    for indice_lista_principal, sublista in enumerate(listas):
        if not encontrado:
            indice_sublista = busqueda_binaria(sublista, elemento_buscado)
            if indice_sublista is not None:
                resultado = (indice_lista_principal, indice_sublista)
                encontrado = True
    return resultado
```
Note que b√°sicamente se esta haciendo una busqueda lineal, la cual ya sabemos que tiene una complejidad temporal de O(n), y dentro de esta se esta buscando las sublistas mediante el m√©todo de busqueda binaria, que es O(log n), lo cual resulta en una complejidad espacial O(n log m)

#### Orden cuadr√°tico O(n2)
- Caracter√≠sticas
    
    - El tiempo de ejecuci√≥n escala con el cuadrado del tama√±o de la entrada
        
    - Tiempo proporcional a n¬≤
        
    - Efectivo para peque√±as entradas,
        
        - Pero impr√°ctico r√°pidamente con grandes vol√∫menes
- Ventajas
    
    - Simple de entender e interpretar
        
    - Eficiente para conjuntos de datos muy peque√±os, con operaciones espec√≠ficas
        
- Desventajas
    
    - Ineficiente para grandes vol√∫menes de datos
Ejemplo:
```run-python
for i in range(n):
    for j in range(n):
        # Expresiones O(1)
```
El hecho de tener dos loops anidados, o dos cosas que dependen de n autom√°ticamente lo hace $O(n^2)$

#### Complejidad temporal - Shaker Sort (1/3)

Estime el orden de crecimiento temporal del siguiente algoritmo:

```run-python
def cocktail_shaker_sort(arr: list[int]) -> None:
    start = 0
    end = len(arr) - 1
    swapped = True

    while swapped:
        swapped = False
        # Movimiento de izquierda a derecha
        for i in range(start, end):
            if arr[i] > arr[i + 1]:
                arr[i], arr[i + 1] = arr[i + 1], arr[i]
                swapped = True
        end -= 1

        # Movimiento de derecha a izquierda
        for i in range(end, start, -1):
            if arr[i] < arr[i - 1]:
                arr[i], arr[i - 1] = arr[i - 1], arr[i]
                swapped = True
        start += 1
```
>[!warning] Ojo el Shaker sort SI ES $O(n^2)$
#### Orden c√∫bico O(n¬≥)

- Caracter√≠sticas
    
    - Tiempo de ejecuci√≥n proporcional al cubo del tama√±o de la entrada
    - Efectivo para peque√±as entradas
        - Pero impr√°ctico r√°pidamente con grandes vol√∫menes
- Ventajas
    
    - Puede ser adecuado para problemas
        - Que requieren operaciones tridimensionales
- Desventajas
    
    - Muy ineficiente a medida que el tama√±o de la entrada crece
```run-python
for i in range(n):
    for j in range(n):
        for k in range(n):
            # Expresiones O(1)
```
```run-python
def buscar_tripletes(lista):
    """
    Encuentra todos los tripletes que sumen cero.

    Args:
        lista (list): lista de n√∫meros enteros.

    Returns:
        list of tuples: lista de tripletes (i, j, k), donde i + j + k == 0.
    """
    triplete = []
    for i in lista: # Se ejecuta n veces
        for j in lista: # Se ejecuta n veces, por cada iteraci√≥n de i
            for k in lista: # Se ejecuta n veces, por cada iteraci√≥n de j
                if i + j + k == 0: # Se ejecuta n * n * n
                    triplete.append((i, j, k)) # Se ejecuta hasta n * n * n
    return triplete
```
#### Orden exponencial O(b‚Åø)

- Caracter√≠sticas
    
    - Crecimiento muy r√°pido
        
        - El tiempo aumenta exponencialmente con el tama√±o de la entrada
        - Tiempo proporcional a `b‚Åø`, donde `b` y `n` son `> 1`
    - T√≠picamente involucra algoritmos que exploran todas las posibilidades
        
- Ventajas
    
    - Apropiado para problemas peque√±os donde se requieren soluciones exhaustivas
- Desventajas
    
    - Generalmente no es viable para grandes vol√∫menes de datos
```run-python
def generar_combinaciones(conjunto):
    """
    Genera todas las combinaciones posibles de un conjunto.
    
    Args:
        conjunto: Lista que representa el conjunto (Ej.:, ["A", "B", "C"])
        
    Retrurns:
        list of lists: Todas las combinaciones posibles
    """
    n = len(conjunto)
    total_combinaciones = 2 ** n  # N√∫mero total de combinaciones
    combinaciones = []

    for i in range(total_combinaciones):
        combinacion_actual = []
        for j in range(n):
            # Verifica si el bit j est√° encendido en el n√∫mero i:
            if i & (1 << j):   
                combinacion_actual.append(conjunto[j])
        combinaciones.append(combinacion_actual)
    return combinaciones
```

#### Aproximaci√≥n emp√≠rica (_a posteriori_ ) (3/3)

```run-python
import time  
  
start_time = time.time()  
  
# Your code or operation to be timed goes here  
# Example:  
sum(range(10**2))  
  
end_time = time.time()  
elapsed_time = end_time - start_time  
  
print(f"Elapsed time: {elapsed_time:.4f} seconds")
```
- "Realismo"¬†
    
    - Mide comportamiento directo¬†
        - Considerando constantes y algunos factores secundarios
- "Sencillez"¬†
    
    - Puede¬† ser m√°s f√°cil de implementar que algunos an√°lisis te√≥ricos
        - Especialmente en algoritmos complejos
### Complejidad Espacial
* Mide la memoria usada por un algoritmo en relaci√≥n al tama√±o de entrada
* Generalmente basado en el peor caso de uso de memoria
* Incluye la memoria usada por
	* Variables 
	* Asignaciones din√°micas
	* ==Estructuras de datos==
#### Espacio constante O(1)
* El espacio no depende del tama√±o de la entrada
```run-python
def suma(num1, num2):
	suma = num1 + num2
	return suma
print(suma(2,2))
```
* Es idenpendiente del tamao de `num1` y `num2`
	* Solo necesita espacio constante para `suma`
#### Espacio lineal O(n)
* El espacio crece linealmente con el tama√±o de la entrada
```run-python
lista = [1,2,3]
def duplicar_lista(lista):
	lista_duplicada = []
	for elemento in lista:
		lista_duplicada.append(elemento * 2)
	return lista_duplicada
print(duplicar_lista(lista))
```
* El espacio necesario para `lista_duplicada` es igual al de la lista que estamos intentando duplicar, por lo tanto **crece linealmente**.
#### Espacio auxiliar
* Memoria adicional aparte de la entrada
```run-python
lista = [5,7,89,3,5]
def ordenar_lista(lista):
	lista_ordenada = sorted(lista)
	return lista_ordenada
print(ordenar_lista(lista))
```
* La `lista_ordenada` es una copia de la lista
	* Resultado en un espacio adicional
		* Proporcional al tama√±o de lista original

>[!question] No entiendo la diferencia entre espacio lineal O(n) y el espacio auxiliar

Diferencia entre **O(n) espacio** y **espacio auxiliar O(n)**
* ***Espacio total**: Toda la memoria que usa el algoritmo (entrada + salida + variables temporales).
* ***Espacio auxiliar**: Memoria **extra** necesaria aparte de la entrada.
* 
| Caso | Entrada (`n`) | Memoria adicional | Espacio total | Espacio auxiliar |
|------|---------------|------------------|---------------|------------------|
| Duplicar lista | `n` | `n` | `O(n)` | `O(n)` |
| Ordenar lista (copia) | `n` | `n` | `O(n)` | `O(n)` |
| Ordenar in-place | `n` | constante | `O(n)` | `O(1)` |

Conclusi√≥n: 
- **O(n) espacio**: Memoria total crece proporcionalmente a `n`.
- **Espacio auxiliar O(n)**: Memoria extra (aparte de la entrada) crece proporcionalmente a `n`.
- Un algoritmo puede tener **espacio total O(n)** pero **auxiliar O(1)** si modifica la entrada directamente.

### Recursividad
- La funci√≥n se invoca a s√≠ misma
    - Para resolver una instancia m√°s peque√±a del problema
- Divide y vencer√°s
    - Descomponer problemas en sub-problemas
- Ejemplo en la vida¬† real ‚Üí Mu√±ecas¬† rusas
    - Versiones m√°s peque√±as anidadas
    - Profundidad finita
#### Componentes importantes
Componentes:
- **Caso base**:
    - Condici√≥n que detiene la recursi√≥n
        - Funci√≥n **no** se invoca a s√≠ misma
- **Caso recursivo**:
    - Funci√≥n se invoca a s√≠ misma
        - En una **versi√≥n m√°s peque√±a** del problema
#### Metodolog√≠a de Desarrollo de software aplicado a recursividad
>[!note] An√°lisis > Dise√±o > Construcci√≥n > Pruebas
1. **An√°lisis**
	1. Identificar y especificar el problema
	2. Identificar restricciones
		1. Se entiende que se debe definir las entradas y salidas de nuestra funci√≥n y sus respectivas restricciones.
	3. Documentar
		1. Note que la documentaci√≥n refleja las **restricciones**
			- `(int)` indica
			    - Que el tipo de dato de entrada esperado es un entero
			    - Que el tipo de dato a retornar es un entero
			- Se especifica la naturaleza positiva de la entrada
		    - El factorial es por definici√≥n positivo
Un ejemplo
```run-python
"""
Calcula el factorial de un n√∫mero (n!).

:param numero: El n√∫mero positivo para calcular su factorial.
:type numero: int

:returns: El factorial del n√∫mero proporcionado.
:rtype: int
"""
```
2. **Dise√±o**
	1. Formular ejemplos
	    - Casos significativos y no redundantes
	2. Dise√±ar el algoritmo
		1. Si el algoritmo es recursivo note que entonces deber√° especificar **caso base** y **caso recursivo**
	3. Dise√±ar y documentar las pruebas
ejemplo se ve as√≠
```run-python
"""
Calcula el factorial de un n√∫mero (n!).

:param numero: El n√∫mero positivo para calcular su factorial.
:type numero: int

:returns: El factorial del n√∫mero proporcionado.
:rtype: int

>>> factorial(0)  # Caso base
1
>>> factorial(1)  # Caso base
1
>>> factorial(2)  # Caso recursivo con 2
2
>>> factorial(3)  # Caso recursivo con 3
6
>>> factorial(4)  # Caso recursivo con 4
24
>>> factorial(5)  # Caso recursivo con 5
120
"""	"""
Calcula el factorial de un n√∫mero (n!).

:param numero: El n√∫mero positivo para calcular su factorial.
:type numero: int

:returns: El factorial del n√∫mero proporcionado.
:rtype: int

>>> factorial(0)  # Caso base
1
>>> factorial(1)  # Caso base
1
>>> factorial(2)  # Caso recursivo con 2
2
>>> factorial(3)  # Caso recursivo con 3
6
>>> factorial(4)  # Caso recursivo con 4
24
>>> factorial(5)  # Caso recursivo con 5
120
"""
```

3. Construcci√≥n 
	1. Codifica/implementa el dise√±o usando
		1. Documentaci√≥n
		2. Convenciones
		3. Buenas pr√°cticas de programaci√≥n
```run-python
def factorial(n):
# Ahora vamos a definir los casos base primero
	if n == 0 or n == 1:
		return 1
# Luego la parte recursiva
	else:
		return n * factorial(n - 1)
```
Sin embargo el c√≥digo siempre se puede pulir m√°s
```run-python
def factorial(n):
    return 1 if n <= 1 else n * factorial(n - 1)
    # Esto aprovechando algo que se conoce como Operador terniario. que hace que sea muy corta la implementaci√≥n. Evalua una expresi√≥n y de concidir una condici√≥n hace algo, de lo contrario hace otra cosa (hace o expresi√≥n1 o expresi√≥n2)
```

Un ejemplo de operador terniario

```run-python
resultado = 'Par' if num % 2 == 0 else 'Impar'
```

Note que primero se eval√∫a la condici√≥n `num % 2 == 0`, luego si esta vale se eval√∫a la expresi√≥n a la izquierda de evaluar `True` y de lo contrar√≠o la que esta a la izquierda.

A diferencia del if, **este es una expresi√≥n**

y puede ser utilizado en asignaciones

4. Finalmente debemos realizar las **pruebas** sobre la implementaci√≥n
	1. Verificar si el resultado obtenido es el esperado
	2. Depurar
		1. Corregir erroes
		2. Pulir/mejorar/optimizar
>[!bug] Aqu√≠ es super importante implementar y ejecutar los ==doctests==

```run-python
import doctest
 
def factorial(n):
    """
    Calcula el factorial de un n√∫mero.
 
    :param n: El n√∫mero positivo para calcular su factorial.
    :type n: int
 
    :returns: El factorial del n√∫mero proporcionado.
    :rtype: int
 
>>> factorial(0)  # Caso base
1
>>> factorial(1)  # Caso base
1
>>> factorial(2)
2
>>> factorial(3)
6
>>> factorial(4)
24
>>> factorial(5)
120
    """
    return 1 if n <= 1 else n * factorial(n - 1)
 
doctest.run_docstring_examples(factorial, globals(), verbose=True)
```
#### Reglas de recursividad
1. Definir el(los) caso(s) base con soluci√≥n conocida
2. Establecer el(los) caso(s) recursivo(s) que resuelvan los sub-problemas
3. Garantizar que los casos recursivos converjan al caso base
4. Si hay m√∫ltiples casos recursivos, deben ser disyuntos
5. La soluci√≥n debe combinar los resultados de los casos base y recursivos

QuizI Implementar la funci√≥n de fibonacci() recursivamente

```
fibonacci(0) = 0
fibonacci(1) = 1
fibonacci(2) = fibonacci(1) + fibonacci(0) = 1 + 0 = 1
fibonacci(3) = fibonacci(2) + fibonacci(1) = 1 + 1 = 2
fibonacci(4) = fibonacci(3) + fibonacci(2) = 2 + 1 = 3
fibonacci(5) = fibonacci(4) + fibonacci(3) = 3 + 2 = 5
‚Ä¶
fibonacci(n) = fibonacci(n‚àí1) + fibonacci(n‚àí2)
```

De nuevo vemos que hay dos casos bases, y podemos usar una estructura similar a la de el factorial

```run-python
def fibonacci(number):
	if number == 0:
		return 0
	elif number == 1:
		return 1
	else:
		return fibonacci(number-1)+fibonacci(number-2)
print(fibonacci(4))
```

ahora esa fue la implementaci√≥n fea, se puede hacer mucho mejor as√≠ 

```run-python
def fibonacci(n):
	return n if n<2 else fibonacci(n-1)+fibonacci(n-2)
print(fibonacci(24))
```


finalmente hay que incluir los docstring

La funci√≥n recursiva de Fibonacci tiene complejidad temporal **O(2^n)**, porque cada llamada genera dos llamadas adicionales, formando un √°rbol de tama√±o exponencial.  
La complejidad espacial es **O(n)**, ya que la pila de llamadas crece hasta una profundidad m√°xima de `n` antes de alcanzar el caso base.

#### Como analizar la complejidad de algoritmos recursivos
- Contabilizar cada operaci√≥n realizada en cada activaci√≥n
    - En cada invocaci√≥n de la funci√≥n
        - Considerar s√≥lo las operaciones dentro de esa activaci√≥n
- Sumar el n√∫mero de operaciones ejecutadas en todas las activaciones
    - Para obtener el total del algoritmo recursivo
En el caso del factorial vemos que tiene una complejidad de $O(n)$ porque cada activaci√≥n va a ir disminuyendo la cuenta final de a `n-1`, lo cual hace que este sea del orden `n` al finalizar.
#### Como analizar la complejidad espacial
##### Pila Stack 
- Estructura de datos con comportamiento LIFO
    - √öltimo en entrar, primero en salir (Last In, First Out)

![[Pasted image 20250811223652.png|center]]

- El Call Stack de Python es una pila
    - Almacena invocaciones a funciones y variables locales


![[Pasted image 20250811223849.png]]


>[!warning] `RecursionError`
>- Excepci√≥n que ocurre cuando:
>	- Una funci√≥n se llama a s√≠ misma demasiadas veces
>- Causa:
>	- Recursi√≥n sin caso base
>		- Solo hay caso recursivo
>	- Funci√≥n mal dise√±ada
>	- La ejecuci√≥n no alcanza el caso base
>- Python limita la profundidad recursiva (**~1000 llamadas**)
>- Ayuda: [RecursionError](https://docs.python.org/3/library/exceptions.html#RecursionError)

##### Solucionar un `RecursionError` tenga en cuenta

- Asegurar que la funci√≥n:
    
    1. Tenga **un caso base**
        
    2. **Avance hacia el o los casos base**
        
        - En cada recursi√≥n
#### Clasificaci√≥n de funciones recursivas (1/4)

- Seg√∫n la ubicaci√≥n de llamada recursiva
	- ==Recursividad directa==
	- ==Recursividad indirecta==
- Seg√∫n el n√∫mero de llamadas recursivas generadas en tiempo de ejecuci√≥n
	- Lineal o simple
		- Ej. factorial
		- Pueden ser pasadas a iterativa
	- No lineal o m√∫ltiple
		- Se generan dos o m√°s llamadas internas
		- Ej. Funci√≥n Fibonacci recusiva
- Seg√∫n la naturaleza de la llamada
    - No hay operaciones despu√©s del llamado a la recursi√≥n √≥
    - Hay operaciones pendientes despu√©s de la recursi√≥n
### Repetici√≥n en Python
#### Iterativa - ciclos
- Utiliza ciclos (como `for` o `while`)
    
    - Para repetir acciones
- Avanza mediante incrementos o decrementos expl√≠citos de variables
    
- Mantiene el estado del c√°lculo en variables temporales
    
- Mantiene un espacio de pila **constante** durante su ejecuci√≥n
* For
```run-python
def factorial(n):
    if n == 0:  # Caso especial:
        return 1
    else:       # Caso general:
        fact = 1
        for i in range(2, n + 1):
            fact *= i
    return fact
```
* While
#### Recursividad
##### Recursivo vs. Iterativo (complejidad espacial)

- **Recursivo**:
    
    - Uso de espacio de pila de llamadas proporcional a `n`
    - Puede llevar a un desbordamiento de la pila para valores muy grandes de `n`
        - Debido a la profundidad de la recursi√≥n
- **Iterativo**:
    
    - Uso de espacio de pila de llamadas constante
    - M√°s eficiente en t√©rminos de memoria para valores grandes de `n`
##### Colas en recursividad 
- **Recursividad final (Tail) - (Iterativa)**:
    
    - La llamada recursiva se realiza como √∫ltima instrucci√≥n dentro de la funci√≥n
        - No hay operaciones pendientes despu√©s de la llamada recursiva
    - Puede optimizarse para volverse recursiva
        - Se puede transformar en un ciclo internamente
    - A este tipo de recursi√≥n se le suele llamar iterativa
- **Recursividad no final (No Tail)**:
    
    - Hay operaciones pendientes despu√©s de la llamada recursiva
## W02M2 aftermath
```run-python

def contar_digitos(n):
    return 1 if n < 10 else contar_digitos(n // 10) + 1

print(contar_digitos(10))  # 2


```
## W02M3 
* ¬øQu√© es un repositorio?
* Es donde se guarda todo el c√≥digo fuente o todos los asets del proyecto.
## W03M2
### Estructuras de datos lineales I
* Secuencia de elementos ordenados 
* Con operaciones de acceso, inserci√≥n y eliminaci√≥n
>[!example] Arreglo y lista enlazada simple (Single linked list)

* Un ejemplo podr√≠a ser la lista de python
	* Secuencia mutable
		* Iterable e indexado
			* Desde 0
	* Retorna su tama√±o
	* Strings, listas y tuplas son todas secuencias
		* Caracteres, otros tipos, solo que una es mutable y la otra no
	* Soportan modificaciones despues de su creaci√≥n
	* Permite **duplicado**
	* ```
	  python[-2,-1,-0] # Es una lista de enteros
	  ```
	* Ahora si, bit
### Bit
* Unidad b√°sica de informaci√≥n
	* Representa un 1 o un 0
	* Luego esta el **Byte** (Que son 8 bits)
		* Agrupaci√≥n
		* Y cada byte tiene una direcci√≥n de memoria √∫nica
### Arreglo
* Estructura de datos
* Almacena elementos secuenciales en memoria contigua
* Por ejemplo el string en python.
* A bajo nivel un string se almacena en el hib que tiene una segmentaci√≥n.
	* Note que cada caracter ocupa **DOS SEGMENTOS**
	* Porque el character unicode necesita estos espacios.
	* Eso quiere decir que por ejemplo el string ```SAMPLE``` ocupa 12 bytes
	* Y la memoria se guarda de forma ==CONTIGUA==
* Ahora los indices que nosotros manejamos no son las direcciones de memoria
	* En este caso los indices son la sumatoria de dos segmentos.
	* Como todas ocupan la misma cantidad de celdas es que podemos acceder a __tiempo constante a cualquier indice__
		* ¬°Esto es una maravilla!
	* >[!example] Para acceder a una celda solo tenemos que hacer ```inicio + tama√±o_celda * indice*``` 
	>Que en este caso es ```2146+2*4```, en el caso en el que el arreglo empieza en el 2146, por el indice por 2. ¬°Note que es por esto que empiezan en el 0!
	> Es por esto que esta operaci√≥n es $O(1)$
	* Todo acceso es $O[1]$, adem√°s el tama√±o de acceso nunca es mayor a 2.
* Python garantiza que todas las celdas sean del mismo tama√±o
	* Si almaceno una lista de strings, entonces ya no se con antelaci√≥n como reservar un espacio fijo para que **sea eficiente**.

#### Arreglo compacto
* Almacena ed forma contigua = compacta
* Por ejemplo los strings,  porque van uno despu√©s del otro
#### Arreglo referencial
* Se guarda en referencias a objetos
* Una lista es un puntero que me manda a cada uno de los objetos que me interesan, algo como si tuvi√©ramos una lista de cosas en obsidian que me mandan a otras p√°ginas.
* ¬ø√ìsea se guarda el texto? **NO**
	* Se guardan referencias
* Por esto podemos tener listas de lo que queramos, porque solo tienen que apuntar.
* Cada una de las referencias toma un espacio √∫nico, de hecho podr√≠an estar en un solo segmento.
* Estas tienen el beneficio de tener accesos que todav√≠a son $O(1)$
##### Referencias inmutables
**Una lista no es m√°s que una referencia apuntando a objetos**
1. Tipo de dato
2. Valor 
3. Identidad
* Note que entonces cuando copiamos las listas, no se tienen que copiar las referencias 
```run-python
original = [1,2]
copy_1 = original[:] # copy_1 = [1,2]
copy_2 = original.copy() # copy_2 = [1,2]
copy_3 = copy.copy(original) # copy_3 = [1,2]
```
* Ahora los enteros son inmutables, entonces el caso donde cambien los numeros no se da
>[!question] ¬øPorque los strings son inmutables
> De lo contrar√≠o, a python le tocar√≠a ver si en el espacio contiguo cobe lo que se esta buscando, entonces tiene que mover TODO a otra posici√≥n de memoria donde si quepa.

* Y las referencias repetidas tampoco representan gasto inecesario de memoria.
>[!example] En el caso de temp de un slicing
> Cuando se genera un slicing, referenciamos lo n√∫meros de prime, pero cuando cambiamos el temp, por ejemplo con ```temp[2]=15``` entonces el **puntero** cambia a apuntar a 15
> **Note que:** Entonces por eso es que una lista saca como objeto un string.


>[!example] ```data = [0]*8 ```
> Esto es un ejemplo de repetici√≥n de listas.
> En este escenario es seguro, pues el 0 no se puede cambiar. **ESTO NO SE DEBE HACER CUANDO SE REFERENCIA UN MUTABLE**
> Uno no hace esto a menos que lo haga con mutables.

* La pregunta ahora, es como hago una inicializaci√≥n segura.
	* ...con un ciclo for... que anticlim√°tico.
##### append y extend
* append agrega una posici√≥n
* Y extend crea referencias para cada uno de los datos de la otra lista
* Note que estas funciones en efecto me generan la necesidad de copiar toda la lista y volver a organizar.
#### Arreglos referenciales vs Arreglos compactos
* Los referenciales tienen un paso m√°s
	* Sin embargo siguen siendo $O[1]$
* La cuesti√≥n de referencia se basa en el espacio que ocupan cada uno, note que en los referenciales van a ocupar m√°s espacio en promedio.
### Complejidad temporal de los arreglos 
* Acceso en arreglos
* La inserci√≥n al inicio interno de arreglos es $O[n]$
	* As√≠ es la vida
* La eliminaci√≥n al inicio tmb va a ser $O[n]$
	* Los arreglos deben ser contiguos, nada que hacer.
* Inserci√≥n al final si es $O[1]$
* Las secuencias en python tienen un tama√±o fijo al crearse
	* `tuples` y `str` son inmutables
	* Pero las `list` si pueden cambiar de tama√±o
	* Python creo sin embargo un arreglo con m√°s espacio, normalmente el doble.
	* El problema es que cuando esto pasa, la inserci√≥n al final ya no es ~~$O[1]$~~, toca copiar y buscar en memoria, como copia cada cosa entonces la complejidad temporal ser√° $O[n]$, pero se llama `O[1] amortizado`.
	* ¬øPero la busqueda de espacio vacios en memor√≠a son O[1]?
		* M√°s o menos, pero se asume que si
* Eliminaci√≥n al final es $O[1]$
	* Implementa facil
	* Eliminar a√∫n m√°s f√°cil
* Toca tener cuidado con el tama√±o inicializado
	* Desplazar es costoso
![[Pasted image 20250819120354.png]]
### Lista como estructura recursiva
* La lista vac√≠a se entiende como el caso base
* Y luego 
- [ ] Ver documentaci√≥n de listas en y espec√≠ficamente de array list

### RAM [[Random Access Memories (10th Anniversary)]]
* Esa es la maravilla del random access memory, por eso tenemos las velocidades que tenemos

### Lista enlazada simple
* Single linked list
* Tiene que tener al menos una cabeza, que apunta hacia el siguiente dato, y el siguiente, hasta que se llega al final.
* De aqu√≠ sale el concepto de cola:
	* Que es la parte final del nodo final
* Note que cada nodo si guarda informaci√≥n
* El recorrido es navegar nodo a nodo desde la cabeza hasta la cola.
	* Y acabo en None.
* **Caracter√≠sticas:**
	* Operaciones comunes
	* Modificable
		*  Se pueden agregar nodos de forma eficiente
	* No indexada
		* No permite acceso directorio a un nodo por √≠ndice.
- Se basa en la colaboraci√≥n de m√∫ltiples objetos en memoria    
- Hay una instancia (objeto):
    - Representa la lista
        - Guarda referencia a la cabeza
- Opcional:
    - Guardar referencia a la cola:
        - Evita recorrer toda la lista
- Opcional:
    - Guardar contador de nodos
        - Evita recorrido total para calcular tama√±o
#### Complejidades
1.  Acceso `O(n)`
	1. No hay indices
	2. Tengo que pararme en la cabeza que es lo √∫nico que se conoce
2. Acceso al inicio `O(1)`
	1. Yo conozco la referencia inicial
	2. Esto es clave para escoger este tipo 
3. Eliminaci√≥n al inicio `O(1)`
4. Inserci√≥n/Eliminaci√≥n interna `O(n)`
5. Inserci√≥n a la cola es `O(n)` a menos que tenga referencia a la cola, en ese casi si es `O(1)`
6. Eliminaci√≥n en la cola es `O(n)` aunque tenga referencia. Pues tengo que devolverme uno y apuntarlo a `None`
## W04M1
![[Pasted image 20250825110838.png]]
* Array list ventajas
	* Implementaci√≥n sencilla
	* Almanecamiento contiguo
	* Eficiente par buscar por √≠ndice
	* Ananir o elimiar es O(1), excepto por la amortizaci√≥n, que no es O(n), pero si es m√°s que O(1)
* Array lists desventajas
	* Redimensionamiento y copiado es necesario
		* Hacer esto es O(n), pues implica copiar todos los elementos
	* Inserci√≥n y eliminaci√≥n es costoso
		* Desplaza elementos O(n)
* Single linked lists ventajas
	* Literalmente solo longitud flexible...
* Single linked lists desventajas
	* Literalmente todo lo dem√°s
* Ojo existe una diferencia entre head-tail lists y las listas enlazadas simples
	* La primera tiene obligatoriamente un puntero a la cola, ganando inserci√≥n al final O(1)
### Tipo de datos abstracto o TAD: Enfoque en **que**, no en el `como`
* TAD
	* Lo que nos permite interactuar entre operaciones
	* Una forma de abstracci√≥n, donde no importa la implementaci√≥n sino del serivcio
* Por ejemplo problema 1 necesita operacion1 y operacion2
* La pregunta es cual estructura va a ser m√°s eficiente para un TAD en es espec√≠fico
* Encapsula los datos y las operaciones permitidas,
	* Se aproxima a un api
* Encapsulamiento
	* Los datos solo se pueden manipular a trav√©s de las operaciones en el TAD, es b√°sicamente una api, entonces todo esta b√°sicamente bien definido desde el inicio
* La estructura de datos si se enfoca en el **c√≥mo**
	* Inserci√≥n en el inicio es necesaria, entonces es claro que se necesita un single linked list
![[Pasted image 20250825112034.png|center]]
#### La pregunta es cual elegir
* Depende del problema
* El tad me dice que requiero una lista
* La estructura de datos me dice que implementaci√≥n de list va a ser la mejor para el TAD en espec√≠fico.
* Note que el tad va a cambiar en funci√≥n del tiempo.
### Estructuras lineales 3
>[!note] Note que en la [documentaci√≥n del curso](https://isis1225devs.github.io/ISIS1225-Structure-Documentation/DataStructures.Graph.html) se realizo con la figura de diccionarios.
> Que pasa si lo hacemos con lista?
#### Primer intento de lista nativa
* Implementaremos `new_list()`, `is_fist()`, `add_list()`
* Primeras dos es `O(1)`
* Pero luego para hacer add_list() note que este a a tener complejidad O(n), pues la concatenaci√≥n nos retorna una nueva lista, por eso a python le toca copiar todo y por eso es O(n). luego si voy al insert, lo mismo, porque tengo que correr todo. Entonces grave porque la complejidad al inicio deber√≠a de O(1), no O(n).
#### Segundo intento, diccionario
* Implementaremos `new_list()`, `is_fist()`, `add_list()`
* Primeras dos es `O(1)` (Un poco m√°s complicado pero bien, es un diccionario con 3 llaves)
* is_empty() es O(1), solo verificamos el size
* finalmente el `add_first()`
	* Creo nuevo nodo, y lo apunto hacia la cabeza, y luego actualizo el puntero de la cabeza.

#### Ejemplo recorrido total de una lista enlazada simple
```run-python
def print_list_info(my_list):
    """
    Imprime la informaci√≥n de cada nodo en una lista simplemente enlazada.

    :param lst: Lista simplemente enlazada.
    :type lst: dict

    :return: Muestra la informaci√≥n en pantalla.
    :rtype: None
    
    >>> my_list = {"first": None, "last": None, "size": 0}
    >>> print_list_info(my_list)

    >>> my_list = {"first": {"info": 10, "next": {"info": 20, "next": {"info": 30, "next": None}}}, "size": 3}
    >>> print_list_info(my_list)
    10
    20
    30
    """
    if my_list["size"] > 0:
        current_node = my_list["first"]
        while current_node is not None:
            print(current_node["info"])
            current_node = current_node["next"]
```
## W04M2
### Lista enlazada doble
* En este escenario podemos devolvernos, ya no es unidireccionar, ahora tenemos apuntadores para el objeto previo, ya no solo para el next.
* Se usa un sentinela, pero no sentinela IP sino tener un header y trailer siempre iguales. 
* Next, prep, next, prep hasta trailer que esta marcado con el fin. directamente.
* Centinela
	* Nos permite simplificar los casos especiales
	* No almacena datos
	* Permanecen inmutables
	* Solo cambian los nodos inbtermedios
	* Son opcionales pero
	* Simplifican la l√≥gica de implementaci√≥n
		* En especial la inserci√≥n o borrado
			* Siempre ser√°n entre nodos existentes.
* Complejidad temporal de la lista enlazada doble
	* El acceso secuencial debe recorrerse nodo por nodo desde la cabeza
	* Sin √≠ndices directos
	* No hay acceso inmediato a alg√∫n nodo espec√≠fico.
	* Entonces es `O(n)`
#### Inserci√≥n al inicio `O(1)`
1. Agregamos un nuevo nodo
2. Luego actualizamos las referencias
	1. Del nodo nuevo hay que apuntarlo al que era el nuevo, a la cabeza
	2. Luego actualizar la vabeza
	3. Finalmente actualizar el viejo al que ahora es el primero.
3. Como son solo actualizaciones O(1)
#### Eliminaci√≥n al inicio `O(1)`
* Acceso inmediato al nodo centinela header
* Actualziar las referencias, del header al next, y el next apuntarlo al header
* Si se gquiere la idea es que el nodo eliminado quitar sus punteros, apuntando a None.
#### Inserci√≥n interna `O(n)` (O eliminaci√≥n interna)
1. Tenemos que iterar hasta el nodo que queremos
2. Crear el nodo
3. Actualizar las cuatro referencias, de los dos nodos de lado y lado
4. Esto es O(n), porque tengo que ir nodo por nodo hasta llegar al que necesitamos
* El problema es que tengo que navegar desde el header o tailer
#### Inserci√≥n/Eliminaci√≥n al final `O(1)`
* Tengo acceso inmediato al final gracias al `trailer`, por lo tanto es una operaci√≥n r√°pida.
* Igual para eliminaci√≥n
#### Beneficio con double vs single
* La eliminaci√≥n al final es O(1) en double vs single que es O(1), lo cual es genial.
### Lista circular
* Cada nodo apunta a otro nodo
	* Formando un ciclo cerrado
* No hay un nodo apuntando a `None`
* Pero sin embargo sigo teniendo un head y un tail, la diferencia es que no tengo `None` al final.
* El problema es saber cuando detenerse
#### Circular single linked list
1. Acceso `O(n)`
	1. No existe acceso directo
	2. Es neesario recorrer todos los nodos hasta encontrar el deseado
	3. Complejidad en el peor caso O(n)
2. Inserci√≥n/Eliminaci√≥n al inicio `O(1)`
	1. Si uno tiene un puntero en la cola
		1. Se enlaza en nuevo nodo con el primero
	2. Misma l√≥gica que anteriormente
3. Inserci√≥n interna `O(n)`
	1. Se puede jugar con cosas, pero igualmente va a dar `O(n)`
4. Eliminaci√≥n al final `O(n)`
	1. Este es un resultado general para los single linked
#### Circular single linked list
1. Eliminaci√≥n al final `O(1)`
	1. √önica ganancia comparado a circular single linked list
### Lista doblemente enlazada vs Lista circular doble
1. Navegaci√≥n continua
	1. En doble se debe reiniciar manualmente
	2. Circular doble permite recorrido continuo
		1. √ötil en buffers, planificaci√≥n, videojuegos
	3. Misma complejidad, diferente utilidad
		1. Eficiencia igual
		2. Navegaci√≥n c√≠clica sin reinicios
			1. Lista circular doble
### Pilas y colas
Estructura de datos de comportamiento LIFO, first to enter, last to leave.
* √öltimo en entrar, primer en salir (Last In, First Out)
* Principales operaciones
	* `push()`
		* A√±ade un elemento al tope de la pila
	* `pop()`
		* Me llevo una bandeja de arriba y me la llevo
	* `top()`
		* Me llevo la bandeja de arriba sin removerlo
### Implementaci√≥n Pila en python
```
# 1 S.push(e) = L.append(e)
#2 S.pop() = L.pop()
#3 S.top() = L[-1]
#4 S.is_empty() = len(L) == 0
#5 len(S) =  len(L)
```
```run-python
# El len funciona como queremos en python
print(len([0,1,2]))

```
1. En este  caso solamente agrego al final, entonecs `O(1)*` amortizado
2. Pop es una eliminaci√≥n al final, no desplaza, `O(1)*` (amortizado)
3. Top, es un acceso por indice, `O(1)`
4. is_empty, es `O(1)`, porque tiene contador
5. len es `O(1)`, yay.

* Es muy eficiente, salvo los casos amoritzados
### Cola
Comportamiento fijo, primero en entrar, primero en salir, es el opuesto de la pila. Es un ascensor b√°sicamente.
1. Enqueue
	1. A√±ade elemento al ==final==.
2. Dequeue
	1. Remueve y retorna elemento del ==frente==.
3. Peek
	1. Retorna elemento del final sin quitarlo. Similar al Dequeue, pero solo consulta.
* Algunos ejemplos son
	* Imprimir elementos 
	* Ascensor
	* Colar
### ~~Cola en python~~ Cola con single linked list
**No se deber√≠a usar**, pues todas las funciones van a ser `O(n)`
1. Enqueue
	1. A√±ade elemento al ==final==.
		1. Se puede implemetar con add_last, `O(1)`
2. Dequeue
	1. Remueve y retorna elemento del ==frente==.
		1. Se puede usar delete_last `O(1)`
3. Peek
	1. Retorna elemento del final sin quitarlo. Similar al Dequeue, pero solo consulta\
		1. remove_first es `O(1)`
# Recap

# Sources
1. https://eerosales24.github.io/eda_2025_20/#/
___